{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6d874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN#\n",
    "def MAIN_RF_MT(data_path,task_list,seed,problem_mode,main_perform,save_file_name):\n",
    "    read_preprocess(data_path,task_list,seed)\n",
    "\n",
    "    q=0\n",
    "    number = list(range(0,500))    \n",
    "    result_df = locals\n",
    "    result_df=pd.DataFrame(index=number)   \n",
    "    \n",
    "    regression_col_list=['Layer','Task' , \n",
    "              'Train_MSE','Train_RMSE','Train_MAE','Train_R2','Train_Pearsonr','Train_Median_AE',            \n",
    "            'Validation_MSE','Validation_RMSE','Validation_MAE','Validation_R2','Validation_Pearsonr','Validation_Median_AE',            \n",
    "            'Test_MSE','Test_RMSE','Test_MAE','Test_R2','Test_Pearsonr','Test_Median_AE']            \n",
    "\n",
    "    classification_col_list=['Layer',  'Task',\n",
    "            'Train AUC', 'Train ACC','Train Balance ACC','Train F1','Train Precision', 'Train Sensitivity','Train Specificity',\n",
    "            'Validation AUC','Validation ACC', 'Validation Balance ACC','Validation F1','Validation Precision','Validation Sensitivity','Validation Specificity',\n",
    "              'Test_AUC', 'Test ACC', 'Test Balance ACC','Test F1',\t 'Test Precision','Test Sensitivity','Test Specificity']\n",
    "    \n",
    "    if problem_mode=='classification':\n",
    "        col_list=classification_col_list\n",
    "    else:\n",
    "        col_list=regression_col_list\n",
    "\n",
    "    decision_df=pd.DataFrame()\n",
    "    i=0\n",
    "    for i in tqdm(range(0,10)):        \n",
    "        if decision_df.empty :\n",
    "            print('----training----'+str(i))  \n",
    "            for label in tqdm(labels):\n",
    "                train_perform(label,i,problem_mode,seed)\n",
    "                for r in range(len(col_list)):\n",
    "                    result_df.at[q,col_list[r]]=result_list[r]\n",
    "                result_df=result_df.round(3)   \n",
    "                q=q+1\n",
    "                \n",
    "            ####修改評估條件######\n",
    "            result_df['Validation '+str(main_perform)]=result_df['Validation '+str(main_perform)].abs()\n",
    "            validation_df_for_mean=result_df.loc[(result_df['Layer']==i)]                   \n",
    "            validation_mean=validation_df_for_mean['Validation '+str(main_perform)].mean(axis=0)\n",
    "            result_df.loc[(result_df['Layer']==i),'Mean '+str(main_perform)]=validation_mean            \n",
    "            result_df['Mean '+str(main_perform)]=result_df['Mean '+str(main_perform)].round(3)\n",
    "                \n",
    "            if main_perform =='AUC' or 'ACC' or 'Balance ACC' or 'F1' or 'Precision' or'Recall'or'Specificity'or'R2'or'Pearsonr':\n",
    "                if (i== 0) or (list(set(result_df.iloc[list(result_df.Layer== i-1) ,-1]))<list(set(result_df.iloc[list(result_df.Layer== i) ,-1]))):        \n",
    "                    evaluation_NF(labels,problem_mode,i)\n",
    "                else:\n",
    "                    print('開始存出Excel')\n",
    "                    result_df=result_df.round(3)\n",
    "                    result_df=result_df.dropna()\n",
    "\n",
    "                    result_df.to_csv('MTRFNET_'+str(save_file_name)+'_result.csv')\n",
    "                    decision_df=result_df\n",
    "                    #count average performance#\n",
    "                    file=result_df\n",
    "                    raw2mean(file,problem_mode,main_perform,save_file_name)                    \n",
    "\n",
    "            else:\n",
    "                if (i== 0) or (list(set(result_df.iloc[list(result_df.Layer== i-1) ,-1]))>list(set(result_df.iloc[list(result_df.Layer== i) ,-1]))):        \n",
    "                    evaluation_NF(labels,problem_mode,i)\n",
    "\n",
    "                else:\n",
    "                    print('開始存出Excel')\n",
    "                    result_df=result_df.round(3)\n",
    "                    result_df=result_df.dropna()\n",
    "\n",
    "                    result_df.to_csv('MTRFNET_'+str(save_file_name)+'_result.csv')\n",
    "                    decision_df=result_df\n",
    "                    #count average performance#\n",
    "                    file=result_df\n",
    "                    raw2mean(file,problem_mode,main_perform,save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f45b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1#\n",
    "def read_preprocess(data_path,task_list,seed):\n",
    "    print('-----preprocessing-----')  \n",
    "    data=pd.read_csv(data_path)   \n",
    "    if 'Unnamed: 0' in data:\n",
    "        data=data.drop(columns=['Unnamed: 0'])\n",
    "    if 'SMILES' in data:\n",
    "        data=data.drop(columns=['SMILES'])\n",
    "    if 'smiles' in data:\n",
    "        data=data.drop(columns=['smiles'])    \n",
    "    if 'mol_id' in data:\n",
    "        data=data.drop(columns=['mol_id'])    \n",
    "\n",
    "###task_list###                   \n",
    "    global labels\n",
    "    labels=task_list\n",
    "\n",
    "    for i in data.index:\n",
    "        for q in labels:\n",
    "            try:\n",
    "                if data.loc[i,q]== 'ACT':\n",
    "                    data.loc[i,q]=int(1)\n",
    "                if data.loc[i,q]== 'INACT':           \n",
    "                    data.loc[i,q]=int(0)             \n",
    "            except:\n",
    "                pass   \n",
    "    for label in labels:\n",
    "        labels_to_drop=[l for l in labels if l !=label]\n",
    "        locals()['Task_'+str(label)]  = data.drop(labels_to_drop,axis=1)  \n",
    "        locals()['Task_'+str(label)]= locals()['Task_'+str(label)].dropna(subset=[label])\n",
    "    for label in labels: \n",
    "        globals()['Task_'+str(label)+'_train_0'],globals()['Task_'+str(label)+'_test_0'] = train_test_split(locals()['Task_'+str(label)], test_size=0.2,random_state=seed ,stratify=locals()['Task_'+str(label)][label])\n",
    "        globals()['Task_'+str(label)+'_train_0'],globals()['Task_'+str(label)+'_valid_0'] = train_test_split(globals()['Task_'+str(label)+'_train_0'], test_size=0.125,random_state=seed ,stratify=globals()['Task_'+str(label)+'_train_0'][label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91928c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2#\n",
    "def train_perform(label,i,problem_mode,seed):    \n",
    "    \n",
    "    y_train=globals()['Task_'+str(label)+'_train_'+str(i)][label].astype('float')\n",
    "    x_train=globals()['Task_'+str(label)+'_train_'+str(i)].drop(columns=label)    \n",
    "    y_valid=globals()['Task_'+str(label)+'_valid_'+str(i)][label].astype('float')\n",
    "    x_valid=globals()['Task_'+str(label)+'_valid_'+str(i)].drop(columns=label)   \n",
    "    y_test=globals()['Task_'+str(label)+'_test_'+str(i)][label].astype('float')\n",
    "    x_test=globals()['Task_'+str(label)+'_test_'+str(i)].drop(columns=label)    \n",
    "    \n",
    "    ##model_parameter##\n",
    "    if problem_mode=='classification':\n",
    "        model_parameter=RandomForestClassifier(n_estimators=500,max_features='log2',random_state=seed,n_jobs=-2)\n",
    "    else:\n",
    "        model_parameter=RandomForestRegressor(n_estimators=500,max_features='log2',random_state=seed,n_jobs=-2)\n",
    "           \n",
    "    x_train=x_train.astype(float)\n",
    "    y_train=y_train.astype(float)    \n",
    "\n",
    "    ##model##\n",
    "    globals()['predictor_'+str(label)+'_'+str(i)]=model_parameter.fit(x_train, y_train)\n",
    "    ###儲存模型###\n",
    "    #joblib.dump(globals()['predictor_'+str(label)+'_'+str(i)], './Zebrafish_Models_withALLMorphology_ECFP6_202310_prob/predictor_'+str(label)+'_'+str(i))\n",
    "\n",
    "    ###    \n",
    "    locals()['y_train_true']=(y_train)\n",
    "    locals()['y_valid_true']=(y_valid)\n",
    "    locals()['y_test_true']=(y_test)\n",
    "\n",
    "    locals()['y_train_pred']=globals()['predictor_'+str(label)+'_'+str(i)].predict(x_train)\n",
    "    locals()['y_valid_pred']=globals()['predictor_'+str(label)+'_'+str(i)].predict(x_valid)\n",
    "    locals()['y_test_pred']=globals()['predictor_'+str(label)+'_'+str(i)].predict(x_test)\n",
    "\n",
    "    locals()['y_prob_train']=globals()['predictor_'+str(label)+'_'+str(i)].predict_proba(x_train)[:, 1]\n",
    "    locals()['y_prob_test']=globals()['predictor_'+str(label)+'_'+str(i)].predict_proba(x_test)[:, 1]\n",
    "    locals()['y_prob_valid']=globals()['predictor_'+str(label)+'_'+str(i)].predict_proba(x_valid)[:, 1]\n",
    "\n",
    "    ##train_performances##\n",
    "    global result_list\n",
    "    result_list=[]\n",
    "    result_list.append(int(i))\n",
    "    result_list.append(label)\n",
    "    \n",
    "    if problem_mode == 'classification':\n",
    "        \n",
    "        p_list=['train','valid','test']\n",
    "        for p in p_list:\n",
    "            \n",
    "            p_true=locals()['y_'+str(p)+'_true']\n",
    "            p_prob=locals()['y_prob_'+str(p)]\n",
    "            p_pred=locals()['y_'+str(p)+'_pred']\n",
    "            \n",
    "            locals()[str(p)+'_AUC'] =metrics.roc_auc_score(p_true,p_prob).round(3) \n",
    "            locals()[str(p)+'_ACC'] =metrics.accuracy_score(p_true, p_pred).round(3)   \n",
    "            locals()[str(p)+'_BACC']=metrics.balanced_accuracy_score(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_F1'] =metrics.f1_score(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_PR'] =metrics.precision_score(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_R']=metrics.recall_score(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_S'] =metrics.recall_score(p_true, p_pred, pos_label=0).round(3)\n",
    "\n",
    "            result_list.append(locals()[str(p)+'_AUC'])\n",
    "            result_list.append(locals()[str(p)+'_ACC'])\n",
    "            result_list.append(locals()[str(p)+'_BACC'])    \n",
    "            result_list.append(locals()[str(p)+'_F1'])\n",
    "            result_list.append(locals()[str(p)+'_PR'])\n",
    "            result_list.append(locals()[str(p)+'_R'])\n",
    "            result_list.append(locals()[str(p)+'_S'])        \n",
    "    else:\n",
    "\n",
    "        p_list=['train','valid','test']\n",
    "        for p in p_list:\n",
    "            \n",
    "            p_true=locals()['y_'+str(p)+'_true']\n",
    "            p_prob=locals()['y_prob_'+str(p)]\n",
    "            p_pred=locals()['y_'+str(p)+'_pred']\n",
    "\n",
    "            locals()[str(p)+'_MSE'] =metrics.mean_squared_error(p_true,p_pred).round(3) \n",
    "            locals()[str(p)+'_RMSE'] =metrics.mean_squared_error(p_true, p_pred, squared=True).round(3)   \n",
    "            locals()[str(p)+'_MAE']=metrics.mean_absolute_error(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_R2'] =metrics.r2_score(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_Pearsonr'] =scipy.stats.pearsonr(p_true, p_pred).round(3)\n",
    "            locals()[str(p)+'_Median_AE'] =metrics.median_absolute_error(y_train_true, y_train_pred).round(3)\n",
    "\t\n",
    "            result_list.append(locals()[str(p)+'_MSE'])\n",
    "            result_list.append(locals()[str(p)+'_RMSE'])\n",
    "            result_list.append(locals()[ str(p)+'_MAE'])    \n",
    "            result_list.append(locals()[str(p)+'_R2'])\n",
    "            result_list.append(locals()[str(p)+'_Pearsonr'])\n",
    "            result_list.append(locals()[str(p)+'_Median_AE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707cfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3#\n",
    "def evaluation_NF(labels,problem_mode,i):   \n",
    "    t_v=['train','valid','test']\n",
    "    ###以第0層df，當作基底增加每層特徵，索以第0層保留###\n",
    "    for tv in t_v:\n",
    "        print('------------'+str(tv)+'-------------')\n",
    "        for Task_name in tqdm(labels):\n",
    "            predict_feature=(globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i)]).drop(columns=[Task_name])\n",
    "            globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)]=globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(0)].copy()\n",
    "\n",
    "            for Task_test in range(len(labels)): \n",
    "                if problem_mode=='classification':\n",
    "                    prob= globals()['predictor_'+str(labels[Task_test])+'_'+str(i)].predict_proba(predict_feature)[:, 1]\n",
    "                else:\n",
    "                    prob= globals()['predictor_'+str(labels[Task_test])+'_'+str(i)].predict(predict_feature)\n",
    "\n",
    "                f = 'new_feature_layer_'+str(i)+'_feature_by_'+str(labels[Task_test])\n",
    "                globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)].loc[:,f]=prob.copy()                       \n",
    "                globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)]=globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)].copy()\n",
    "                globals()['Task_check'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)]=globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i+1)].copy()\n",
    "\n",
    "       ##釋出不需要的variable##\n",
    "    if i!=0:\n",
    "        for tv in t_v:\n",
    "            print('----釋出variable----'+str(tv)+'-------------')\n",
    "            for Task_name in tqdm(labels):\n",
    "                del globals()['Task_'+str(Task_name)+'_'+str(tv)+'_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba71687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4#\n",
    "def raw2mean(file,problem_mode,main_perform,save_file_name):\n",
    "    file['Layer']=file['Layer'].astype(int)\n",
    "    file=file.dropna()\n",
    "\n",
    "    number = list(range(0,500))\n",
    "    result_mean_df=pd.DataFrame(index=number )\n",
    "\n",
    "    regression_col_list=['Layer' , \n",
    "              'Train_MSE','Train_RMSE','Train_MAE','Train_R2','Train_Pearsonr','Train_Median_AE',            \n",
    "            'Validation_MSE','Validation_RMSE','Validation_MAE','Validation_R2','Validation_Pearsonr','Validation_Median_AE',            \n",
    "            'Test_MSE','Test_RMSE','Test_MAE','Test_R2','Test_Pearsonr','Test_Median_AE']            \n",
    "\n",
    "    classification_col_list=['Layer',  \n",
    "            'Train AUC', 'Train ACC','Train Balance ACC','Train F1','Train Precision', 'Train Recall','Train Specificity',\n",
    "            'Validation AUC','Validation ACC', 'Validation Balance ACC','Validation F1','Validation Precision','Validation Recall','Validation Specificity',\n",
    "              'Test_AUC', 'Test ACC', 'Test Balance ACC','Test F1',\t 'Test Precision','Test Recall','Test Specificity']\n",
    "    \n",
    "    if problem_mode=='classification':\n",
    "        col_list=classification_col_list\n",
    "    else:\n",
    "        col_list=regression_col_list\n",
    "    \n",
    "    col_list=classification_col_list\n",
    "    col_list.append('#Mean>0.8')\n",
    "    \n",
    "    file_layer=file['Layer'].unique()\n",
    "    file_layer=file_layer.tolist()\n",
    "    mean_list=locals \n",
    "    ###各層平均###\n",
    "    a=0\n",
    "    for i in file_layer:\n",
    "\n",
    "        file_layer=file['Layer'].unique()\n",
    "\n",
    "        layer_len=len(file_layer)\n",
    "        file_layer=file[file['Layer']==i]\n",
    "        if problem_mode=='classification':\n",
    "            file_class=file_layer.iloc[:,2:23]\n",
    "        else:\n",
    "            file_class=file_layer.iloc[:,2:20]            \n",
    "                         \n",
    "        mean_list=file_class.mean()\n",
    "        mean_list=mean_list.round(3)\n",
    "        mean_list=list(mean_list)\n",
    "        task_number=file_class[file_class['Test_'+str(main_perform)]>=0.8]\n",
    "        noft=list(task_number['Test_'+str(main_perform)])\n",
    "        noft=len(noft)       \n",
    "        mean_list.insert(0,i)\n",
    "        mean_list.append(noft)\n",
    "        for r in range(len(col_list)):\n",
    "            result_mean_df.loc[a,col_list[r]]=mean_list[r]\n",
    "        a=a+1\n",
    "\n",
    "    result_mean_df=result_mean_df.dropna()    \n",
    "    result_mean_df.to_csv('MTRFNET_'+str(save_file_name)+'_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34169e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "任務型態:classification\n",
      "評估指標:AUC\n",
      "-----preprocessing-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----training----0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/48 [00:03<02:29,  3.18s/it]\u001b[A\n",
      "  4%|▍         | 2/48 [00:06<02:22,  3.09s/it]\u001b[A\n",
      "  6%|▋         | 3/48 [00:09<02:20,  3.12s/it]\u001b[A\n",
      "  8%|▊         | 4/48 [00:12<02:17,  3.13s/it]\u001b[A\n",
      " 10%|█         | 5/48 [00:15<02:15,  3.16s/it]\u001b[A\n",
      " 12%|█▎        | 6/48 [00:18<02:12,  3.14s/it]\u001b[A\n",
      " 15%|█▍        | 7/48 [00:21<02:08,  3.12s/it]\u001b[A\n",
      " 17%|█▋        | 8/48 [00:25<02:04,  3.12s/it]\u001b[A\n",
      " 19%|█▉        | 9/48 [00:28<02:01,  3.11s/it]\u001b[A\n",
      " 21%|██        | 10/48 [00:31<01:57,  3.10s/it]\u001b[A\n",
      " 23%|██▎       | 11/48 [00:34<01:55,  3.13s/it]\u001b[A\n",
      " 25%|██▌       | 12/48 [00:37<01:53,  3.14s/it]\u001b[A\n",
      " 27%|██▋       | 13/48 [00:40<01:49,  3.11s/it]\u001b[A\n",
      " 29%|██▉       | 14/48 [00:43<01:46,  3.12s/it]\u001b[A\n",
      " 31%|███▏      | 15/48 [00:46<01:44,  3.15s/it]\u001b[A\n",
      " 33%|███▎      | 16/48 [00:50<01:40,  3.14s/it]\u001b[A\n",
      " 35%|███▌      | 17/48 [00:53<01:37,  3.14s/it]\u001b[A\n",
      " 38%|███▊      | 18/48 [00:56<01:33,  3.13s/it]\u001b[A\n",
      " 40%|███▉      | 19/48 [00:59<01:30,  3.13s/it]\u001b[A\n",
      " 42%|████▏     | 20/48 [01:02<01:28,  3.15s/it]\u001b[A\n",
      " 44%|████▍     | 21/48 [01:05<01:24,  3.15s/it]\u001b[A\n",
      " 46%|████▌     | 22/48 [01:08<01:19,  3.05s/it]\u001b[A\n",
      " 48%|████▊     | 23/48 [01:11<01:16,  3.08s/it]\u001b[A\n",
      " 50%|█████     | 24/48 [01:14<01:14,  3.11s/it]\u001b[A\n",
      " 52%|█████▏    | 25/48 [01:18<01:11,  3.13s/it]\u001b[A\n",
      " 54%|█████▍    | 26/48 [01:21<01:09,  3.14s/it]\u001b[A\n",
      " 56%|█████▋    | 27/48 [01:24<01:05,  3.12s/it]\u001b[A\n",
      " 58%|█████▊    | 28/48 [01:27<01:02,  3.12s/it]\u001b[A\n",
      " 60%|██████    | 29/48 [01:30<00:59,  3.12s/it]\u001b[A\n",
      " 62%|██████▎   | 30/48 [01:33<00:56,  3.12s/it]\u001b[A\n",
      " 65%|██████▍   | 31/48 [01:36<00:53,  3.14s/it]\u001b[A\n",
      " 67%|██████▋   | 32/48 [01:39<00:49,  3.12s/it]\u001b[A\n",
      " 69%|██████▉   | 33/48 [01:43<00:46,  3.12s/it]\u001b[A\n",
      " 71%|███████   | 34/48 [01:46<00:43,  3.13s/it]\u001b[A\n",
      " 73%|███████▎  | 35/48 [01:49<00:40,  3.14s/it]\u001b[A\n",
      " 75%|███████▌  | 36/48 [01:52<00:37,  3.15s/it]\u001b[A\n",
      " 77%|███████▋  | 37/48 [01:55<00:34,  3.15s/it]\u001b[A\n",
      " 79%|███████▉  | 38/48 [01:58<00:31,  3.15s/it]\u001b[A\n",
      " 81%|████████▏ | 39/48 [02:01<00:28,  3.14s/it]\u001b[A\n",
      " 83%|████████▎ | 40/48 [02:05<00:25,  3.15s/it]\u001b[A\n",
      " 85%|████████▌ | 41/48 [02:08<00:21,  3.14s/it]\u001b[A\n",
      " 88%|████████▊ | 42/48 [02:11<00:18,  3.14s/it]\u001b[A\n",
      " 90%|████████▉ | 43/48 [02:14<00:15,  3.15s/it]\u001b[A\n",
      " 92%|█████████▏| 44/48 [02:17<00:12,  3.13s/it]\u001b[A\n",
      " 94%|█████████▍| 45/48 [02:20<00:09,  3.13s/it]\u001b[A\n",
      " 96%|█████████▌| 46/48 [02:23<00:06,  3.13s/it]\u001b[A\n",
      " 98%|█████████▊| 47/48 [02:27<00:03,  3.24s/it]\u001b[A\n",
      "100%|██████████| 48/48 [02:29<00:00,  3.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/48 [00:13<10:24, 13.29s/it]\u001b[A\n",
      "  4%|▍         | 2/48 [00:26<10:08, 13.23s/it]\u001b[A\n",
      "  6%|▋         | 3/48 [00:39<09:52, 13.17s/it]\u001b[A\n",
      "  8%|▊         | 4/48 [00:52<09:40, 13.19s/it]\u001b[A\n",
      " 10%|█         | 5/48 [01:06<09:28, 13.23s/it]\u001b[A\n",
      " 12%|█▎        | 6/48 [01:20<09:37, 13.74s/it]\u001b[A\n",
      " 15%|█▍        | 7/48 [01:34<09:16, 13.56s/it]\u001b[A\n",
      " 17%|█▋        | 8/48 [01:47<08:58, 13.46s/it]\u001b[A\n",
      " 19%|█▉        | 9/48 [02:00<08:42, 13.39s/it]\u001b[A\n",
      " 21%|██        | 10/48 [02:13<08:26, 13.32s/it]\u001b[A\n",
      " 23%|██▎       | 11/48 [02:26<08:12, 13.30s/it]\u001b[A\n",
      " 25%|██▌       | 12/48 [02:40<07:58, 13.30s/it]\u001b[A\n",
      " 27%|██▋       | 13/48 [02:53<07:44, 13.28s/it]\u001b[A\n",
      " 29%|██▉       | 14/48 [03:06<07:30, 13.26s/it]\u001b[A\n",
      " 31%|███▏      | 15/48 [03:19<07:18, 13.27s/it]\u001b[A\n",
      " 33%|███▎      | 16/48 [03:33<07:03, 13.24s/it]\u001b[A\n",
      " 35%|███▌      | 17/48 [03:46<06:50, 13.25s/it]\u001b[A\n",
      " 38%|███▊      | 18/48 [03:59<06:38, 13.27s/it]\u001b[A\n",
      " 40%|███▉      | 19/48 [04:12<06:23, 13.23s/it]\u001b[A\n",
      " 42%|████▏     | 20/48 [04:26<06:10, 13.22s/it]\u001b[A\n",
      " 44%|████▍     | 21/48 [04:39<05:56, 13.21s/it]\u001b[A\n",
      " 46%|████▌     | 22/48 [04:49<05:19, 12.28s/it]\u001b[A\n",
      " 48%|████▊     | 23/48 [05:02<05:13, 12.55s/it]\u001b[A\n",
      " 50%|█████     | 24/48 [05:15<05:05, 12.74s/it]\u001b[A\n",
      " 52%|█████▏    | 25/48 [05:28<04:56, 12.89s/it]\u001b[A\n",
      " 54%|█████▍    | 26/48 [05:42<04:46, 13.02s/it]\u001b[A\n",
      " 56%|█████▋    | 27/48 [05:55<04:35, 13.10s/it]\u001b[A\n",
      " 58%|█████▊    | 28/48 [06:08<04:23, 13.17s/it]\u001b[A\n",
      " 60%|██████    | 29/48 [06:22<04:10, 13.18s/it]\u001b[A\n",
      " 62%|██████▎   | 30/48 [06:35<03:57, 13.19s/it]\u001b[A\n",
      " 65%|██████▍   | 31/48 [06:48<03:44, 13.21s/it]\u001b[A\n",
      " 67%|██████▋   | 32/48 [07:01<03:31, 13.25s/it]\u001b[A\n",
      " 69%|██████▉   | 33/48 [07:15<03:18, 13.22s/it]\u001b[A\n",
      " 71%|███████   | 34/48 [07:28<03:05, 13.23s/it]\u001b[A\n",
      " 73%|███████▎  | 35/48 [07:41<02:51, 13.23s/it]\u001b[A\n",
      " 75%|███████▌  | 36/48 [07:54<02:38, 13.21s/it]\u001b[A\n",
      " 77%|███████▋  | 37/48 [08:07<02:25, 13.23s/it]\u001b[A\n",
      " 79%|███████▉  | 38/48 [08:21<02:12, 13.24s/it]\u001b[A\n",
      " 81%|████████▏ | 39/48 [08:34<01:59, 13.29s/it]\u001b[A\n",
      " 83%|████████▎ | 40/48 [08:47<01:46, 13.25s/it]\u001b[A\n",
      " 85%|████████▌ | 41/48 [09:01<01:32, 13.26s/it]\u001b[A\n",
      " 88%|████████▊ | 42/48 [09:14<01:19, 13.30s/it]\u001b[A\n",
      " 90%|████████▉ | 43/48 [09:27<01:06, 13.28s/it]\u001b[A\n",
      " 92%|█████████▏| 44/48 [09:40<00:52, 13.25s/it]\u001b[A\n",
      " 94%|█████████▍| 45/48 [09:54<00:39, 13.25s/it]\u001b[A\n",
      " 96%|█████████▌| 46/48 [10:07<00:26, 13.31s/it]\u001b[A\n",
      " 98%|█████████▊| 47/48 [10:22<00:13, 13.82s/it]\u001b[A\n",
      "100%|██████████| 48/48 [10:32<00:00, 13.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------valid-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/48 [00:09<07:41,  9.81s/it]\u001b[A\n",
      "  4%|▍         | 2/48 [00:19<07:28,  9.75s/it]\u001b[A\n",
      "  6%|▋         | 3/48 [00:29<07:29,  9.98s/it]\u001b[A\n",
      "  8%|▊         | 4/48 [00:39<07:16,  9.92s/it]\u001b[A\n",
      " 10%|█         | 5/48 [00:49<07:02,  9.83s/it]\u001b[A\n",
      " 12%|█▎        | 6/48 [00:59<06:53,  9.85s/it]\u001b[A\n",
      " 15%|█▍        | 7/48 [01:08<06:40,  9.78s/it]\u001b[A\n",
      " 17%|█▋        | 8/48 [01:18<06:31,  9.78s/it]\u001b[A\n",
      " 19%|█▉        | 9/48 [01:28<06:23,  9.82s/it]\u001b[A\n",
      " 21%|██        | 10/48 [01:38<06:16,  9.90s/it]\u001b[A\n",
      " 23%|██▎       | 11/48 [01:48<06:07,  9.92s/it]\u001b[A\n",
      " 25%|██▌       | 12/48 [01:58<05:57,  9.94s/it]\u001b[A\n",
      " 27%|██▋       | 13/48 [02:08<05:47,  9.92s/it]\u001b[A\n",
      " 29%|██▉       | 14/48 [02:18<05:37,  9.93s/it]\u001b[A\n",
      " 31%|███▏      | 15/48 [02:28<05:29,  9.97s/it]\u001b[A\n",
      " 33%|███▎      | 16/48 [02:38<05:16,  9.89s/it]\u001b[A\n",
      " 35%|███▌      | 17/48 [02:47<05:06,  9.88s/it]\u001b[A\n",
      " 38%|███▊      | 18/48 [02:57<04:55,  9.85s/it]\u001b[A\n",
      " 40%|███▉      | 19/48 [03:07<04:44,  9.82s/it]\u001b[A\n",
      " 42%|████▏     | 20/48 [03:17<04:33,  9.76s/it]\u001b[A\n",
      " 44%|████▍     | 21/48 [03:26<04:22,  9.74s/it]\u001b[A\n",
      " 46%|████▌     | 22/48 [03:36<04:09,  9.61s/it]\u001b[A\n",
      " 48%|████▊     | 23/48 [03:46<04:02,  9.71s/it]\u001b[A\n",
      " 50%|█████     | 24/48 [03:55<03:54,  9.76s/it]\u001b[A\n",
      " 52%|█████▏    | 25/48 [04:05<03:45,  9.80s/it]\u001b[A\n",
      " 54%|█████▍    | 26/48 [04:15<03:35,  9.79s/it]\u001b[A\n",
      " 56%|█████▋    | 27/48 [04:25<03:26,  9.81s/it]\u001b[A\n",
      " 58%|█████▊    | 28/48 [04:35<03:15,  9.75s/it]\u001b[A\n",
      " 60%|██████    | 29/48 [04:52<03:11, 10.07s/it]\u001b[A\n",
      "  0%|          | 0/10 [17:54<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m任務型態:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(problem_mode))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m評估指標:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(main_perform))\n\u001b[0;32m---> 51\u001b[0m \u001b[43mMAIN_RF_MT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mproblem_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmain_perform\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m end\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m執行時間: \u001b[39m\u001b[38;5;124m'\u001b[39m,end \u001b[38;5;241m-\u001b[39m start)\n",
      "Cell \u001b[0;32mIn[1], line 46\u001b[0m, in \u001b[0;36mMAIN_RF_MT\u001b[0;34m(data_path, task_list, seed, problem_mode, main_perform, save_file_name)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m main_perform \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalance ACC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPearsonr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(result_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mlist\u001b[39m(result_df\u001b[38;5;241m.\u001b[39mLayer\u001b[38;5;241m==\u001b[39m i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) ,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m<\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(result_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mlist\u001b[39m(result_df\u001b[38;5;241m.\u001b[39mLayer\u001b[38;5;241m==\u001b[39m i) ,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))):        \n\u001b[0;32m---> 46\u001b[0m         \u001b[43mevaluation_NF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mproblem_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m開始存出Excel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mevaluation_NF\u001b[0;34m(labels, problem_mode, i)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Task_test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)): \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m problem_mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m         prob\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictor_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTask_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_feature\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         prob\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictor_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(labels[Task_test])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)]\u001b[38;5;241m.\u001b[39mpredict(predict_feature)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    871\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    872\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m    874\u001b[0m ]\n\u001b[1;32m    875\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m--> 876\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[1;32m    882\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from resource import getrusage, RUSAGE_SELF\n",
    "\n",
    "##########################################################\n",
    "##1 random seed##\n",
    "global seed\n",
    "seed=8 #Ex:8\n",
    "\n",
    "##2 檔案路徑##\n",
    "#data_path=('')#Ex:'Zebrafish_Tasks_Dataset.csv'#\n",
    "data_path=('Zebrafish_final202310_withMorphologyALLdata_ECFP6.csv')\n",
    "\n",
    "##3 所有任務名稱##\n",
    "#task_list=[]#Ex:['Label_name1','Label_name2','Label_name3'....]#\n",
    "\n",
    "task_list=['LEL_MORT','LEL_YSE','LEL_AXIS','LEL_EYE','LEL_SNOU', 'LEL_JAW',\n",
    "'LEL_OTIC','LEL_PE','LEL_BRAI','LEL_SOMI','LEL_PFIN','LEL_CFIN',\n",
    "'LEL_PIG','LEL_CIRC', 'LEL_TRUN','LEL_SWIM','LEL_NC','LEL_TR', '18_END_LEC', 'MOR_LEC','SUBLETH_17_END_LEC', 'TOX_SCO',\n",
    "'MO24', 'DP24', 'SM24', 'NC24','MORT','YSE', 'AXIS', 'EYE',\n",
    "'SNOU', 'JAW', 'OTIC', 'PE', 'BRAI', 'SOMI', 'PFIN', 'CFIN',\n",
    "'PIG','CIRC', 'TRUN', 'SWIM','NC','TR','MOV21', 'AUC21','METAB','MIC']\n",
    "\n",
    "##4 結果儲存檔案名稱##\n",
    "save_file_name='test' #Ex:'pk'#\n",
    "\n",
    "###5 ####\n",
    "problem_mode='classification'\n",
    "#classification,regression#\n",
    "\n",
    "###6主要評估指標####\n",
    "main_perform='AUC'\n",
    "# 'AUC', ' ACC',' Balance ACC',' F1',' Precision', ' Recall',' Specificity','MSE','RMSE','MAE','R2','Pearsonr','Median_AE'#         \n",
    "\n",
    "##以下不用修改##\n",
    "import time\n",
    "start=time.time()\n",
    "print('任務型態:'+str(problem_mode))\n",
    "print('評估指標:'+str(main_perform))\n",
    "MAIN_RF_MT(data_path,task_list,seed,problem_mode,main_perform,save_file_name)\n",
    "end=time.time()\n",
    "print('執行時間: ',end - start)\n",
    "print(\"peak memory:\", getrusage(RUSAGE_SELF).ru_maxrss / 1000 / 1000, \"MB\")\n",
    "\n",
    "#目前使用的參數#\n",
    "#資料比例:7:1:2\n",
    "#Validation:Independet\n",
    "#RF:n_estimators=500,max_features='log2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3c636-462d-4664-853a-9ef00982a505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
